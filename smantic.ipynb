{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/vchabaux/Smantic/blob/main/smantic.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "pLNGodPrKK6T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUK7BEL7c-Gc",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Instalation des packages\n",
        "!pip install salesforce-lavis &> /dev/null\n",
        "!pip install faiss-cpu &> /dev/null\n",
        "!pip install xmltodict &> /dev/null\n",
        "!pip install gradio &> /dev/null\n",
        "exit()\n",
        "print(\"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üüß **WAIT RESTART** üüß\n",
        "**Attendez que l'environnement red√©marre avant de lancer les cellules suivantes**"
      ],
      "metadata": {
        "id": "0VlJdVuVHhGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration GoogleDrive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "SMANTIC_DIR = \"drive/MyDrive/smantic/\""
      ],
      "metadata": {
        "id": "CQ_wVsEQ37GM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "from enum import Enum\n",
        "import os\n",
        "from math import dist\n",
        "import time\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import csv\n",
        "import requests\n",
        "import xmltodict\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import faiss\n",
        "import numpy as np\n",
        "from lavis.models import load_model_and_preprocess\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "import ast\n",
        "import sys\n",
        "import traceback\n",
        "import io\n",
        "import gradio as gr\n",
        "\n",
        "class SearchMantic:\n",
        "    class Source(Enum):\n",
        "        \"\"\"Type de corpus\n",
        "\n",
        "        Args:\n",
        "            Enum (str): Type possible de corpus √† traiter\n",
        "        \"\"\"\n",
        "        ARK = \"Ark\"\n",
        "        URL = \"Url\"\n",
        "        LOCAL = \"Local\"\n",
        "\n",
        "    def __init__(self):\n",
        "        os.chdir(os.path.dirname(os.path.abspath(\"__file__\")))\n",
        "\n",
        "        self.translationModelName = 'Helsinki-NLP/opus-mt-fr-en'\n",
        "        self.blip2ModelName = 'Salesforce/blip2-opt-2.7b-coco'\n",
        "\n",
        "        self.default_batch_size = 1\n",
        "\n",
        "        self.arkColName = \"ark\"\n",
        "        self.urlImageColName = \"image\"\n",
        "        self.LegendColName = \"legend\"\n",
        "        self.LocalImageColName = \"local_image\"\n",
        "        self.EnLegendColName = \"en_legend\"\n",
        "        self.LegendEmbeddingColName = \"legend_embedding\"\n",
        "        self.ImageEmbeddingColName = \"image_embedding\"\n",
        "\n",
        "        self.indexsDirName = \"INDEXS\"\n",
        "        self.imagesDirname = \"IMAGES\"\n",
        "        self.datasetsDirname = \"TMP\"\n",
        "\n",
        "        self.indexsDir = SMANTIC_DIR + self.indexsDirName\n",
        "        self.imagesDir = SMANTIC_DIR + self.imagesDirname\n",
        "        self.datasetsDir = SMANTIC_DIR + self.datasetsDirname\n",
        "\n",
        "        self.device = self.get_device()\n",
        "        self.CPU = \"cpu\"\n",
        "\n",
        "        self.create_directories()\n",
        "        self.load_models()\n",
        "        self.get_local_indexs()\n",
        "\n",
        "    def create_directories(self):\n",
        "        if not os.path.exists(self.indexsDir):\n",
        "            os.makedirs(self.indexsDir)\n",
        "        if not os.path.exists(self.imagesDir):\n",
        "            os.makedirs(self.imagesDir)\n",
        "        if not os.path.exists(self.datasetsDirname):\n",
        "            os.makedirs(self.datasetsDirname)\n",
        "\n",
        "    def nombre_pages(self, ark):\n",
        "        \"\"\"Retourne le nombre de pages du document)\n",
        "\n",
        "        Args:\n",
        "            ark (str): Identifiant ark\n",
        "\n",
        "        Returns:\n",
        "            int: Nombre de pages dans le document\n",
        "        \"\"\"\n",
        "        # In : identifiant ark | Out : nombre de pages (int)\n",
        "        PAGINATION_BASEURL = 'https://gallica.bnf.fr/services/Pagination?ark='\n",
        "        url = \"\".join([PAGINATION_BASEURL, ark])\n",
        "\n",
        "        s = requests.get(url, stream=True)\n",
        "\n",
        "        paginationdic = xmltodict.parse(s.text)\n",
        "        nb_pages = int(paginationdic[\"livre\"][\"structure\"][\"nbVueImages\"])\n",
        "        return nb_pages\n",
        "\n",
        "    def rect_distance(self, rect1, rect2):\n",
        "        \"\"\"Calcul la distance entre le milieu-bas du rectangle superieur (image) et le milieu-haut du rectangle inferieur(l√©gende)\n",
        "\n",
        "        Args:\n",
        "            rect1 ([int]): Coordon√©es de l'image\n",
        "            rect2 ([int]): Coordonn√©es de la possible l√©gende\n",
        "\n",
        "        Returns:\n",
        "            float: Distance entre\n",
        "        \"\"\"\n",
        "        x1, y1, x1b, y1b = rect1\n",
        "        x2, y2, x2b, y2b = rect2\n",
        "        # Coordonn√©es des milieux des c√¥t√©s\n",
        "        milieu_haut_rect2 = ((x2 + x2b) / 2, y2)\n",
        "        milieu_bas_rect1 = ((x1 + x1b) / 2, y1b)\n",
        "        # Calcul de la distance entre les milieux\n",
        "        distance = dist(milieu_haut_rect2, milieu_bas_rect1)\n",
        "        return distance\n",
        "\n",
        "    def get_device(self):\n",
        "        \"\"\"D√©tecte la pr√©sence d'un GPU\n",
        "\n",
        "        Returns:\n",
        "            _type_: _description_\n",
        "        \"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"Using GPU : {torch.cuda.get_device_name(0)}\")\n",
        "            device = torch.device(\"cuda:0\")\n",
        "        else:\n",
        "            print(\"Using CPU\")\n",
        "            device = torch.device(\"cpu\")\n",
        "        return device\n",
        "    def reload_indexes(self):\n",
        "        self.indexs = {filename: os.path.join(self.indexsDir, filename)  for filename in os.listdir(self.indexsDir) if filename.endswith(\".smantic\")}\n",
        "\n",
        "    def get_local_indexs(self):\n",
        "        \"\"\"Liste les corpus index√©s disponibles\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.indexsDir):\n",
        "            os.makedirs(self.indexsDir)\n",
        "            print(f\"\\nLe dossier d'indexs {self.indexsDir} n'existe pas et a √©t√© cr√©√©.\")\n",
        "        #print(f\"\\nDossier d'indexs : {self.indexsDir}\")\n",
        "        _index_file_names = os.listdir(self.indexsDir)\n",
        "        #self.indexs = {{filename: os.path.join(self.indexsDir, filename)} for filename in _index_file_names if filename.endswith(\".smantic\")}\n",
        "        self.indexs = {filename: os.path.join(self.indexsDir, filename)  for filename in _index_file_names if filename.endswith(\".smantic\")}\n",
        "        #print(f\"\\t{len(self.indexs)} corpus trouv√©(s)\")\n",
        "        #for index in self.indexs:\n",
        "            #print(f\"\\t\\t- {index[0]} : {index[1]}\")\n",
        "\n",
        "    def load_corpus(self, corpus_name):\n",
        "        print(f\"Loading {corpus_name}\")\n",
        "        options = [\"Image\"]\n",
        "        with zipfile.ZipFile(self.indexs[corpus_name], \"r\") as zipf:\n",
        "            _serialized_index_image = zipf.read(\"cpu_image.index\")\n",
        "            try:\n",
        "                _serialized_index_legend = zipf.read(\"cpu_legend.index\")\n",
        "                _serialized_index_mean = zipf.read(\"cpu_mean.index\")\n",
        "\n",
        "                options+=[\"Texte & Image\"]\n",
        "                options+=[\"Texte\"]\n",
        "            except:\n",
        "                pass\n",
        "            with zipf.open(\"dataset.csv\") as dataframe_file:\n",
        "                self.dataset = pd.read_csv(dataframe_file)\n",
        "\n",
        "        _serialized_index_image = BytesIO(_serialized_index_image)\n",
        "        _serialized_index_image = np.frombuffer(_serialized_index_image.getvalue(), dtype=np.uint8)\n",
        "        self.index_image = faiss.deserialize_index(_serialized_index_image)\n",
        "        print(\"Image index deserialized\")\n",
        "\n",
        "        try:\n",
        "\n",
        "            _serialized_index_legend = BytesIO(_serialized_index_legend)\n",
        "            _serialized_index_legend = np.frombuffer(_serialized_index_legend.getvalue(), dtype=np.uint8)\n",
        "            self.index_legend = faiss.deserialize_index(_serialized_index_legend)\n",
        "            print(\"Legend index deserialized\")\n",
        "\n",
        "            _serialized_index_mean = BytesIO(_serialized_index_mean)\n",
        "            _serialized_index_mean = np.frombuffer(_serialized_index_mean.getvalue(), dtype=np.uint8)\n",
        "            self.index_mean = faiss.deserialize_index(_serialized_index_mean)\n",
        "            print(\"Mean index deserialized\")\n",
        "            print(f\"'{corpus_name}' loaded\")\n",
        "        except:pass\n",
        "        return options\n",
        "\n",
        "    def embedd_input(self, input_txt, translate = True):\n",
        "\n",
        "        if translate:\n",
        "            print(\"Input translation\")\n",
        "\n",
        "            input_txt = self.translation_tokenizer(input_txt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            input_txt = input_txt.to(self.device)\n",
        "            input_txt = self.translation_model.generate(**input_txt)\n",
        "            input_txt = self.translation_tokenizer.decode(input_txt[0], skip_special_tokens=True)\n",
        "            print(\"Input translation done.\")\n",
        "        print(\"Input Embdding\")\n",
        "        sample = {\"text_input\": input_txt}\n",
        "        text_emb = self.blip2_model.extract_features(sample, mode=\"text\").text_embeds_proj[:,0,:] # size (1, 256)\n",
        "        text_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
        "        print(\"Input embedding done.\")\n",
        "        return text_emb\n",
        "\n",
        "    def search_sim_images(self, input_embedding, search_type, img_count, use_local_images = True):\n",
        "        if search_type == \"legend_embedding\":\n",
        "            index = self.index_legend\n",
        "        elif search_type == \"image_embedding\":\n",
        "            index = self.index_image\n",
        "        else:\n",
        "            index = self.index_mean\n",
        "        distances, indices = index.search(input_embedding.cpu(), img_count)\n",
        "        distances = distances[0]\n",
        "        indices = indices[0]\n",
        "\n",
        "        indices_distances = list(zip(indices, distances))\n",
        "        indices_distances.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        if use_local_images and self.LocalImageColName in self.dataset.columns:\n",
        "            print([SMANTIC_DIR+self.dataset.loc[indices,self.LocalImageColName] for indices, distances in indices_distances])\n",
        "            if \"MyDrive\" in self.dataset.loc[0, self.LocalImageColName]:\n",
        "              if self.LegendColName in self.dataset.columns:\n",
        "                  return [(Image.open(self.dataset.loc[indices, self.LocalImageColName]).convert(\"RGB\"), f\"{distances} - {self.dataset.loc[indices, self.LegendColName]}\") for indices, distances in indices_distances]\n",
        "              elif self.EnLegendColName in self.dataset.columns:\n",
        "                  return [(Image.open(self.dataset.loc[indices, self.LocalImageColName]).convert(\"RGB\"), f\"{distances} - {self.dataset.loc[indices, self.EnLegendColName]}\") for indices, distances in indices_distances]\n",
        "              else:\n",
        "                  return [(Image.open(self.dataset.loc[indices, self.LocalImageColName]).convert(\"RGB\"), f\"{distances}\") for indices, distances in indices_distances]\n",
        "            else:\n",
        "              if self.LegendColName in self.dataset.columns:\n",
        "                  return [(Image.open(SMANTIC_DIR+self.dataset.loc[indices, self.LocalImageColName]).convert(\"RGB\"), f\"{distances} - {self.dataset.loc[indices, self.LegendColName]}\") for indices, distances in indices_distances]\n",
        "              elif self.EnLegendColName in self.dataset.columns:\n",
        "                  return [(Image.open(SMANTIC_DIR+self.dataset.loc[indices, self.LocalImageColName]).convert(\"RGB\"), f\"{distances} - {self.dataset.loc[indices, self.EnLegendColName]}\") for indices, distances in indices_distances]\n",
        "              else:\n",
        "                  return [(Image.open(SMANTIC_DIR+self.dataset.loc[indices, self.LocalImageColName]).convert(\"RGB\"), f\"{distances}\") for indices, distances in indices_distances]\n",
        "\n",
        "        elif self.urlImageColName in self.dataset.columns:\n",
        "            print([self.dataset.loc[indices,self.urlImageColName] for indices, distances in indices_distances])\n",
        "\n",
        "            if self.LegendColName in self.dataset.columns:\n",
        "                return [(Image.open(requests.get(self.dataset.loc[indices, self.urlImageColName], stream=True).raw), f\"{distances} - {self.dataset.loc[indices, self.LegendColName]}\") for indices, distances in indices_distances]\n",
        "            elif self.EnLegendColName in self.dataset.columns:\n",
        "                return [(Image.open(requests.get(self.dataset.loc[indices, self.urlImageColName], stream=True).raw), f\"{distances} - {self.dataset.loc[indices, self.EnLegendColName]}\") for indices, distances in indices_distances]\n",
        "            else:\n",
        "                return [(Image.open(requests.get(self.dataset.loc[indices, self.urlImageColName], stream=True).raw), f\"{distances}\") for indices, distances in indices_distances]\n",
        "\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Charge les models de traduction et d'embedding\n",
        "        \"\"\"\n",
        "        print(\"Loading translation model...\")\n",
        "        self.translation_tokenizer = MarianTokenizer.from_pretrained(self.translationModelName, device_map=self.device)\n",
        "        self.translation_model = MarianMTModel.from_pretrained(self.translationModelName)\n",
        "        self.translation_model.to(self.device)\n",
        "        #self.translation_model = self.translation_model.to(self.device)\n",
        "        print(\"Done.\")\n",
        "\n",
        "        print(\"Loading Blip2 model...\")\n",
        "        self.blip2_model, self.blip2_image_processor, self.blip2_text_processor = load_model_and_preprocess(name=\"blip2_feature_extractor\", model_type=\"coco\", device=self.device)\n",
        "        #self.blip2_tokenizer = AutoTokenizer.from_pretrained(self.blip2ModelName, device_map='auto', torch_dtype = torch.float16)\n",
        "        #self.blip2_model = Blip2Model.from_pretrained(self.blip2ModelName, device_map='auto', torch_dtype = torch.float16)\n",
        "        #self.blip2_processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\", device_map='auto', torch_dtype = torch.float16)\n",
        "        print(\"Done.\")\n",
        "\n",
        "    def get_data_from_arks(self, arks, corpus_name):\n",
        "        \"\"\"Collecte les images et les l√©gendes dans les pages des documents ark sur Gallica\n",
        "\n",
        "        Args:\n",
        "            arks ([str]): Liste d'identifiants ark  sur  Gallica\n",
        "            corpus_name (str): Nom du corpus\n",
        "        \"\"\"\n",
        "        if os.path.exists(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\")):\n",
        "            os.remove(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\"))\n",
        "        with open(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\"), \"a\", encoding='utf-8') as data_file:\n",
        "            csv_writer = csv.writer(data_file)\n",
        "            csv_writer.writerow([self.urlImageColName, self.LegendColName])\n",
        "            for ark in arks:\n",
        "                print(\"\\nARK :\", ark)\n",
        "                links = {}\n",
        "                try:\n",
        "                    pages = self.nombre_pages(ark)\n",
        "                except:\n",
        "                    print(f\"Pas de page trouv√© pour {ark}. Skipped\")\n",
        "                    continue\n",
        "\n",
        "                for page in range(1, pages+1) :\n",
        "                    images = []\n",
        "                    texts = []\n",
        "                    alto_url = 'https://gallica.bnf.fr/RequestDigitalElement?O={}&E=ALTO&Deb={}'.format(ark, page)\n",
        "                    # Boucle de requ√™te de l'alto de la page. Si erreur sleep 15 secondes. Skip la page √† la 3eme erreur\n",
        "                    fail_counter = 0\n",
        "                    while True:\n",
        "                        try:\n",
        "                            s = requests.get(alto_url, stream=True)\n",
        "                            break\n",
        "                        except:\n",
        "                            fail_counter += 1\n",
        "                            if fail_counter > 2:\n",
        "                                print(\"Echec de collecte de l'alto avec l'url :\", alto_url, \"Echecs:\", fail_counter)\n",
        "                                print(\"Top d'echecs, page is skiped\")\n",
        "                                break\n",
        "                            else:\n",
        "                                print(\"Echec de collecte de l'alto avec l'url :\", alto_url, \"Echecs:\", fail_counter)\n",
        "                                print(\"Nouvel essai dans 15 secondes\")\n",
        "                                time.sleep(15)\n",
        "                                continue\n",
        "\n",
        "                    # V√©rifier si la page est est oc√©ris√©e, sinon la page est skiped\n",
        "                    try:\n",
        "                        altodic = xmltodict.parse(s.text)\n",
        "                    except :\n",
        "                        print(ark, \"Document non oc√©ris√©. Skiped\")\n",
        "                        break\n",
        "\n",
        "                    # Collecte des images et l√©gendes\n",
        "                    print(\"==========\", \"Page\", page,\"==========\")\n",
        "                    cbs = altodic[\"alto\"][\"Layout\"][\"Page\"].get(\"PrintSpace\", {}).get(\"TextBlock\", [])\n",
        "                    if not isinstance(cbs, list): cbs = [cbs]\n",
        "\n",
        "                    for cb in cbs:\n",
        "                        content = []\n",
        "                        textLines = cb.get(\"TextLine\",[])\n",
        "                        if not isinstance(textLines, list): textLines = [textLines]\n",
        "                        for textLine in textLines:\n",
        "                            strings = textLine.get(\"String\",[])\n",
        "                            if not isinstance(strings, list): strings = [strings]\n",
        "                            content.extend(string.get(\"@CONTENT\") for string in strings)\n",
        "                        texts.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])), \" \".join(content)))\n",
        "\n",
        "                    cbs = altodic[\"alto\"][\"Layout\"][\"Page\"].get(\"PrintSpace\", {}).get(\"Illustration\", [])\n",
        "                    if not isinstance(cbs, list): cbs = [cbs]\n",
        "                    for cb in cbs:\n",
        "                        images.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])), cb))\n",
        "\n",
        "                    cbs = altodic[\"alto\"][\"Layout\"][\"Page\"].get(\"PrintSpace\", {}).get(\"ComposedBlock\", [])\n",
        "                    if not isinstance(cbs, list): cbs = [cbs]\n",
        "                    for cb in cbs:\n",
        "                        illustration = cb.get(\"Illustration\", [])\n",
        "                        if not isinstance(illustration, list):\n",
        "                            illustration = [illustration]\n",
        "                        textBlocks = cb.get(\"TextBlock\", [])\n",
        "                        if not isinstance(textBlocks, list):\n",
        "                            textBlocks = [textBlocks]\n",
        "                        for cb in textBlocks:\n",
        "                            content = []\n",
        "                            textLines = cb.get(\"TextLine\",[])\n",
        "                            if not isinstance(textLines, list):\n",
        "                                textLines = [textLines]\n",
        "                            for textLine in textLines:\n",
        "                                strings = textLine.get(\"String\",[])\n",
        "                                if not isinstance(strings, list): strings = [strings]\n",
        "                                content.extend(string.get(\"@CONTENT\") for string in strings)\n",
        "                            texts.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])), \" \".join(content)))\n",
        "                        for cb in illustration:\n",
        "                            images.append(((int(cb[\"@HPOS\"]), int(cb[\"@VPOS\"]), int(cb[\"@HPOS\"])+int(cb[\"@WIDTH\"]), int(cb[\"@VPOS\"])+int(cb[\"@HEIGHT\"])),cb))\n",
        "\n",
        "                    # R√©cup√©rer toutes les images (et leur l√©gende) identifi√©es sur la page\n",
        "                    for i,img in enumerate(images) :\n",
        "                        url = \"https://gallica.bnf.fr/iiif/ark:/12148/{}/f{}/{},{},{},{}/{}/0/native.jpg\".format(ark,page,img[1][\"@HPOS\"],img[1][\"@VPOS\"],img[1][\"@WIDTH\"],img[1][\"@HEIGHT\"],\"full\")\n",
        "\n",
        "                        # Identifier et r√©cup√©rer la l√©gende de l'image (si trouv√©e)\n",
        "                        txt_rank = []\n",
        "                        legend = []\n",
        "                        for txt in texts:\n",
        "                            distance = self.rect_distance(img[0], txt[0])\n",
        "                            if distance <100 : legend.append(txt[1])\n",
        "                            txt_rank.append((distance, txt[1]))\n",
        "                        txt_rank.sort(key= lambda x : x[0])\n",
        "                        if legend != []:\n",
        "                            txt_legned = \" \".join(legend)\n",
        "                        else:\n",
        "                            txt_legend = None\n",
        "                        print(\"Image :\", i, \"| Description :\", txt_legned)\n",
        "                        csv_writer.writerow([url, txt_legned])\n",
        "\n",
        "    def create_new_corpus(self, corpus_name, csv_path, translate_legends = True, translation_batch_size = None, embedding_batch_size = None, keep_images = True, sep=\";\", col_ark=None):\n",
        "        \"\"\"Cr√©er un nouveau corpus d'images et de l√©gendes √† rechercher :\n",
        "            - Collecte des urls pour les corpus d'identifiants arks\n",
        "            - Traduction des l√©gendes si option activ√©e\n",
        "            - Embedding des l√©gendes (si pr√©sentes)\n",
        "            - Embedding des images\n",
        "            - Cr√©ationdes l'index FAISS √† 3 canaux\n",
        "            - Sauvegarde de l'index\n",
        "\n",
        "        Args:\n",
        "            corpus_name (str): Nom du corpus\n",
        "            csv_path (str): chemin du fichier csv de corpus\n",
        "            translate_legends (bool, optional): Traduire les l√©gendes. Defaults to True.\n",
        "            translation_batch_size (int, optional): Taille du batch pour la traduction. Defaults to None.\n",
        "            embedding_batch_size (int, optional): Taille du batch pour les embeddings. Defaults to None.\n",
        "        \"\"\"\n",
        "        if translation_batch_size is None:\n",
        "            translation_batch_size = self.default_batch_size\n",
        "        if embedding_batch_size is None:\n",
        "            embedding_batch_size = self.default_batch_size\n",
        "\n",
        "        print(f\"\\nCr√©ation du corpus \\\"{corpus_name}\\\" √† partir de \\\"{csv_path}\\\"\")\n",
        "        corpus_dataframe = pd.read_csv(csv_path, encoding=\"utf-8\", sep = sep)\n",
        "        \"\"\"\n",
        "        if self.arkColName in corpus_dataframe.columns:\n",
        "            source = self.Source.ARK\n",
        "        elif self.urlImageColName in corpus_dataframe.columns:\n",
        "            source = self.Source.URL\n",
        "        elif self.LocalImageColName in corpus_dataframe.columns:\n",
        "            source = self.Source.LOCAL\n",
        "        else:\n",
        "            print(\"Erreur : Impossible de d√©finir le type de source.\")\n",
        "            return\n",
        "        \"\"\"\n",
        "        #print(f\"\\tType de source d√©tect√© : {source.value}\")\n",
        "\n",
        "        arks = corpus_dataframe[col_ark].tolist()\n",
        "        if len(arks) == 0:\n",
        "            print(\"Erreur : Aucun ark touv√©\")\n",
        "            return\n",
        "        else:\n",
        "            print(f\"\\t{len(arks)} arks trouv√©s\")\n",
        "            self.get_data_from_arks(arks, corpus_name)\n",
        "        corpus_csv_path = os.path.join(self.datasetsDir, f\"{corpus_name}.csv\")\n",
        "\n",
        "        self.create_new_index(corpus_name,\n",
        "                              csv_file = corpus_csv_path,\n",
        "                              translate_legends = translate_legends,\n",
        "                              translation_batch_size = translation_batch_size,\n",
        "                              embedding_batch_size = embedding_batch_size,\n",
        "                              keep_images=keep_images,\n",
        "                              img_col = self.urlImageColName,\n",
        "                              legend_col=self.LegendColName,\n",
        "                              _sep=\",\",\n",
        "                              local=False)\n",
        "\n",
        "    def create_new_index(self, corpus_name, csv_file, translate_legends = True, translation_batch_size = None, embedding_batch_size = None, keep_images=True, img_col = None, legend_col=None, _sep=\";\", local=False):\n",
        "        \"\"\" Cr√©e un index FAISS pour un corpus embedd√©.\n",
        "\n",
        "        Args:\n",
        "            corpus_name (str): Nom du corpus\n",
        "            csv_file (str): path du corpus csv\n",
        "            translate_legends (bool, optional): Traduire les l√©gendes du corpus du fran√ßaos vers l'anglais. Defaults to True.\n",
        "            translation_batch_size (int, optional): Taille du batch pour la traducrion. Defaults to None.\n",
        "            embedding_batch_size (int, optional): Taille du batch pour les embeddings (textes et images). Defaults to None.\n",
        "        \"\"\"\n",
        "\n",
        "        dataset = pd.read_csv(csv_file, encoding =\"utf-8\", sep=_sep)\n",
        "        if translate_legends is True:\n",
        "            dataset = dataset.rename(columns={legend_col: self.LegendColName})\n",
        "        elif translate_legends is False:\n",
        "            dataset = dataset.rename(columns={legend_col: self.EnLegendColName})\n",
        "            print(\"titi\",legend_col, local)\n",
        "        if local is False:\n",
        "            dataset = dataset.rename(columns={img_col: self.urlImageColName})\n",
        "        else:\n",
        "            dataset = dataset.rename(columns={img_col: self.LocalImageColName})\n",
        "\n",
        "\n",
        "\n",
        "        if translation_batch_size is None:\n",
        "            translation_batch_size = self.default_batch_size\n",
        "        if embedding_batch_size is None:\n",
        "            embedding_batch_size = self.default_batch_size\n",
        "\n",
        "        # Traduction des legendes (s'il y a des l√©gendes et que l'optio de traduction est activ√©e)\n",
        "        if self.LegendColName in dataset.columns and translate_legends and not self.EnLegendColName in dataset.columns :\n",
        "            print(\"Traduction des l√©gendes...\")\n",
        "            num_batches = len(dataset) // translation_batch_size + 1\n",
        "            batches = [dataset.iloc[i*translation_batch_size:(i+1)*translation_batch_size] for i in range(num_batches)]\n",
        "            dataset = pd.concat([self.translate_legend(batch) for batch in batches])\n",
        "            print(\"Done.\")\n",
        "            dataset.to_csv(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\"), encoding =\"utf-8\", index=False)\n",
        "\n",
        "        if self.EnLegendColName in dataset.columns :\n",
        "            print(\"toto\")\n",
        "            legendForEmbedding = self.EnLegendColName\n",
        "        elif self.LegendColName in dataset.columns:\n",
        "            legendForEmbedding = self.LegendColName\n",
        "        else:\n",
        "            legendForEmbedding = None\n",
        "        print(legendForEmbedding)\n",
        "        print(dataset.columns)\n",
        "        # Embedding des legendes\n",
        "        if legendForEmbedding is not None and self.LegendEmbeddingColName not in dataset.columns:\n",
        "            num_batches = len(dataset) // embedding_batch_size + 1\n",
        "            batches = [dataset.iloc[i*embedding_batch_size:(i+1)*embedding_batch_size] for i in range(num_batches)]\n",
        "            dataset = pd.concat([self.legendsEmbedding(batch, legendForEmbedding) for batch in batches])\n",
        "            dataset.to_csv(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\"), encoding =\"utf-8\", index=False)\n",
        "\n",
        "        # Embedding des images\n",
        "        if not self.ImageEmbeddingColName in dataset.columns:\n",
        "            if keep_images:\n",
        "                IIIF_folder_path = os.path.join(self.imagesDir, corpus_name)\n",
        "                if not os.path.exists(IIIF_folder_path):\n",
        "                    os.makedirs(IIIF_folder_path)\n",
        "                else:\n",
        "                    #shutil.rmtree(IIIF_folder_path)\n",
        "                    os.makedirs(IIIF_folder_path)\n",
        "\n",
        "            num_batches = len(dataset) // embedding_batch_size + 1\n",
        "            batches = [dataset.iloc[i*embedding_batch_size:(i+1)*embedding_batch_size] for i in range(num_batches)]\n",
        "            dataset = pd.concat([self.imagesEmbedding(batch, corpus_name, keep_images, local) for batch in batches])\n",
        "            dataset.to_csv(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\"), encoding =\"utf-8\", index=False)\n",
        "\n",
        "        # Cr√©ation des indexs\n",
        "        print(\"Cr√©ation des indexs\")\n",
        "        if legendForEmbedding is not None:\n",
        "\n",
        "            array = np.array(dataset[self.LegendEmbeddingColName].apply(lambda x:ast.literal_eval(str(x))).to_list())\n",
        "            cpu_index = faiss.IndexFlatIP(array.shape[1])\n",
        "            cpu_index.add(array)\n",
        "            serialized_index_legend = faiss.serialize_index(cpu_index)\n",
        "            serialized_index_legend = BytesIO(serialized_index_legend)\n",
        "\n",
        "            legend_array = np.array(dataset[self.LegendEmbeddingColName].apply(lambda x:ast.literal_eval(str(x))).to_list())\n",
        "            image_array = np.array(dataset[self.ImageEmbeddingColName].apply(lambda x:ast.literal_eval(str(x))).to_list())\n",
        "            array_mean = (legend_array + image_array) / 2\n",
        "            cpu_index = faiss.IndexFlatIP(array_mean.shape[1])\n",
        "            cpu_index.add(array_mean)\n",
        "            serialized_index_mean = faiss.serialize_index(cpu_index)\n",
        "            serialized_index_mean = BytesIO(serialized_index_mean)\n",
        "\n",
        "        array = np.array(dataset[self.ImageEmbeddingColName].apply(lambda x:ast.literal_eval(str(x))).to_list())\n",
        "        cpu_index = faiss.IndexFlatIP(array.shape[1])\n",
        "        cpu_index.add(array)\n",
        "        serialized_index_image = faiss.serialize_index(cpu_index)\n",
        "        serialized_index_image = BytesIO(serialized_index_image)\n",
        "\n",
        "\n",
        "        print(f\"Cr√©tions des indexs pour {corpus_name}\")\n",
        "        dataset = pd.read_csv(os.path.join(self.datasetsDir, f\"{corpus_name}.csv\"), encoding =\"utf-8\")\n",
        "        dataset_buffer = BytesIO()\n",
        "        dataset.to_csv(dataset_buffer, index=False, encoding=\"utf-8\")\n",
        "        dataset_buffer.seek(0)\n",
        "\n",
        "        with zipfile.ZipFile(os.path.join(self.indexsDir,f\"{corpus_name}.smantic\"), \"w\") as zipf:\n",
        "            if legendForEmbedding is not None:\n",
        "                zipf.writestr(\"cpu_legend.index\", serialized_index_legend.getvalue())\n",
        "                zipf.writestr(\"cpu_mean.index\", serialized_index_mean.getvalue())\n",
        "            zipf.writestr(\"cpu_image.index\", serialized_index_image.getvalue())\n",
        "            zipf.writestr(\"dataset.csv\", dataset_buffer.getvalue())\n",
        "        print(\"Done.\")\n",
        "        print(f\"Index file : {corpus_name}.smantic\")\n",
        "\n",
        "    def translate_legend(self, batch):\n",
        "        \"\"\"Traduit les l√©gendes par batch\n",
        "\n",
        "        Args:\n",
        "            batch (pd.DataFrame): Batch du corpus pour la traduction\n",
        "        Returns:\n",
        "            pd.DataFrame: Batch du corpuis traduit.\n",
        "        \"\"\"\n",
        "        legends = batch[self.LegendColName].fillna(\"\").tolist()\n",
        "        legends_tokenized = self.translation_tokenizer(legends, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        legends_tokenized = legends_tokenized.to(self.device)\n",
        "        translated_tokenized = self.translation_model.generate(**legends_tokenized)\n",
        "        en_legends = [self.translation_tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokenized]\n",
        "        batch = batch.copy()\n",
        "        batch[self.EnLegendColName] = en_legends\n",
        "        print(\"\\n\\tTranslation batch done.\")\n",
        "        return batch\n",
        "\n",
        "    def legendsEmbedding(self, batch, legendForEmbedding):\n",
        "        \"\"\"Embedding des l√©gendes par batch\n",
        "\n",
        "        Args:\n",
        "            batch (pd.DataFrame): Batch du corpus pour l'embedding des l√©gendes\n",
        "            legendForEmbedding (str): Nom de la colonne de l√©gende pour l'embedding\n",
        "        Returns:\n",
        "            pd.DataFrame: Batch du corpuis avec les l√©gendes embedd√©s.\n",
        "        \"\"\"\n",
        "        #text_proj = nn.Linear(2560, 256, device = self.device, dtype=torch.float16)\n",
        "        base = batch[legendForEmbedding].fillna(\"\").tolist()\n",
        "        #inputs_text = self.blip2_tokenizer(base, padding=True, return_tensors=\"pt\")\n",
        "        #inputs_text = inputs_text.to(self.device)\n",
        "        #text_features = self.blip2_model.get_text_features(**inputs_text, output_hidden_states = True)\n",
        "        #text_embeddings = F.normalize(text_proj(text_features.hidden_states[-1][:, -1, :]), dim=-1, )\n",
        "\n",
        "        text_input = [self.blip2_text_processor[\"eval\"](txt) for txt in base]\n",
        "        sample = {\"text_input\": text_input}\n",
        "\n",
        "        text_emb = self.blip2_model.extract_features(sample, mode=\"text\").text_embeds_proj[:,0,:] # size (1, 256)\n",
        "        text_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        batch = batch.copy()\n",
        "        batch[self.LegendEmbeddingColName] = text_emb.tolist()\n",
        "        print(\"\\n\\tLegend embedding batch done.\")\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def imagesEmbedding(self, batch, corpus_name, keep_images = False, local=False):\n",
        "        \"\"\"Embedding des images par batch\n",
        "\n",
        "        Args:\n",
        "            batch (pd.DataFrame): Batch du corpus pour l'embedding des images\n",
        "        Returns:self.LocalImageColName\n",
        "            pd.DataFrame: Batch du corpuis avec les images embedd√©s.\n",
        "        \"\"\"\n",
        "        #text_proj = nn.Linear(1408, 256, device = self.device, dtype=torch.float16)\n",
        "        if local is True:\n",
        "            base = batch[self.LocalImageColName].tolist()\n",
        "        else:\n",
        "            base = batch[self.urlImageColName].tolist()\n",
        "        indexs = batch.index.values.tolist()\n",
        "        print(base)\n",
        "        local_image_paths = []\n",
        "        retry_count = 3\n",
        "        while True:\n",
        "            try:\n",
        "                if local is False:\n",
        "                    local_image_paths = []\n",
        "                    local_image_paths_short_list = []\n",
        "                    images = []\n",
        "                    for i,image_url in enumerate(base):\n",
        "                        img = requests.get(image_url, stream=True).content\n",
        "                        images.append(img)\n",
        "\n",
        "                        if keep_images:\n",
        "                            local_image_path = os.path.join(self.imagesDir, corpus_name,f\"{indexs[i]}.jpg\")\n",
        "                            local_image_path_short = os.path.join(self.imagesDirname, corpus_name,f\"{indexs[i]}.jpg\")\n",
        "                            local_image_paths.append(local_image_path)\n",
        "                            local_image_paths_short_list.append(local_image_path_short)\n",
        "                            with open(local_image_path, 'wb') as out_file:\n",
        "                                shutil.copyfileobj(io.BytesIO(img), out_file)\n",
        "                    samples = [{\"image\": self.blip2_image_processor[\"eval\"](Image.open(io.BytesIO(image)).convert(\"RGB\")).unsqueeze(0).to(self.device)} for image in images]\n",
        "                    base_images = [self.blip2_model.extract_features(sample, mode=\"image\").image_embeds_proj[:,0,:].tolist()[0] for sample in samples]\n",
        "                else:\n",
        "                    samples = [{\"image\": self.blip2_image_processor[\"eval\"](Image.open(image).convert(\"RGB\")).unsqueeze(0).to(self.device)} for image in base]\n",
        "                    base_images = [self.blip2_model.extract_features(sample, mode=\"image\").image_embeds_proj[:,0,:].tolist()[0] for sample in samples]\n",
        "                break\n",
        "            except Exception:\n",
        "                print(traceback.format_exc())\n",
        "                if retry_count > 0:\n",
        "                    print(\"Error : retry in 15 seconds.\")\n",
        "                    print(f\"{retry_count} retry before skip\")\n",
        "                    retry_count-=1\n",
        "                    time.sleep(15)\n",
        "                else:\n",
        "                    print(f\"Error - images skipped\")\n",
        "                    break\n",
        "        batch = batch.copy()\n",
        "        batch[self.ImageEmbeddingColName] = base_images\n",
        "        if keep_images and local is False:\n",
        "            batch[self.LocalImageColName] = local_image_paths_short_list\n",
        "        elif local is True:\n",
        "            batch[self.LocalImageColName] = base\n",
        "\n",
        "        print(\"\\n\\tImage embedding batch done.\")\n",
        "\n",
        "        return batch\n",
        "\n",
        "class Logger:\n",
        "    def __init__(self, filename):\n",
        "        self.terminal = sys.stdout\n",
        "        self.log = open(filename, \"w\")\n",
        "\n",
        "    def write(self, message):\n",
        "        self.terminal.write(message)\n",
        "        self.log.write(message)\n",
        "\n",
        "    def flush(self):\n",
        "        self.terminal.flush()\n",
        "        self.log.flush()\n",
        "\n",
        "    def isatty(self):\n",
        "        return False\n",
        "print(\"OK\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z3L4_2Ps-Nb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Lancer l'interface\n",
        "\n",
        "def main():\n",
        "    #sys.stdout = Logger(\"output.log\")\n",
        "\n",
        "    def read_logs():\n",
        "        sys.stdout.flush()\n",
        "        with open(\"output.log\", \"r\") as f:\n",
        "            return f.read()\n",
        "\n",
        "    type_search = {\n",
        "        \"Texte & Image\":\"mean_embedding\",\n",
        "        \"Image\":\"image_embedding\",\n",
        "        \"Texte\":\"legend_embedding\"\n",
        "    }\n",
        "\n",
        "    smantic = SearchMantic()\n",
        "\n",
        "    def search_csv_fn(coll_name_image, file_image, dropdown_image, keep_local_image, file_sep_image, r2, dropdown_legend, r):\n",
        "        if r == \"Urls\":\n",
        "            local=False\n",
        "        else:\n",
        "            local=True\n",
        "        if file_sep_image == '[ , ] virgule':\n",
        "            sep = \",\"\n",
        "        else:\n",
        "            sep= \";\"\n",
        "\n",
        "        if r2 == \"Pas de l√©gende\":\n",
        "            col_lgd=None\n",
        "            trad = None\n",
        "        elif r2 == \"Fran√ßais\":\n",
        "            trad = True\n",
        "            col_lgd=dropdown_legend\n",
        "        else:\n",
        "            trad=False\n",
        "            col_lgd=dropdown_legend\n",
        "        smantic.create_new_index(coll_name_image, file_image, trad, translation_batch_size = 3, embedding_batch_size = 3, keep_images=keep_local_image, _sep=sep, img_col=dropdown_image, legend_col=col_lgd, local=local)\n",
        "\n",
        "    def search_dir_fn(coll_name_dir_img, img_dir, use_filename_dir):\n",
        "        img_dir = img_dir.replace(\"\\\\\",\"/\")\n",
        "        noms_fichiers = [os.path.join(img_dir, fichier) for fichier in os.listdir(img_dir) if fichier[::-1].split(\".\",1)[0][::-1].lower() in [\"png\",\"jpg\",\"jpeg\"]]\n",
        "        noms_seulement = [fichier for fichier in os.listdir(img_dir) if fichier[::-1].split(\".\",1)[0][::-1].lower() in [\"png\",\"jpg\",\"jpeg\"]]\n",
        "\n",
        "        if(use_filename_dir):\n",
        "            df = pd.DataFrame({smantic.LocalImageColName: noms_fichiers, smantic.LegendColName: noms_seulement})\n",
        "            legend_col=smantic.LegendColName\n",
        "        else:\n",
        "            df = pd.DataFrame({smantic.LocalImageColName: noms_fichiers})\n",
        "            legend_col=None\n",
        "        csv_file_name=smantic.datasetsDirname+\"/\"+coll_name_dir_img+\".csv\"\n",
        "\n",
        "        df.to_csv(csv_file_name, encoding=\"utf-8\")\n",
        "        smantic.create_new_index(coll_name_dir_img, csv_file_name, translate_legends=True, translation_batch_size = 3, embedding_batch_size = 3, keep_images=True, _sep=\",\", img_col=smantic.LocalImageColName, legend_col=legend_col, local=True)\n",
        "\n",
        "\n",
        "    def search_ark_fn(coll_name_ark, file_ark, dropdown_ark, keep_local_ark, file_sep_ark):\n",
        "        smantic.create_new_corpus(coll_name_ark, file_ark, translation_batch_size=3, embedding_batch_size=3, keep_images = keep_local_ark, sep=file_sep_ark, col_ark=dropdown_ark)\n",
        "\n",
        "    def deactivate():\n",
        "        return gr.update(interactive=False), gr.update(interactive=False),gr.update(interactive=False), gr.update(interactive=False),gr.update(interactive=False), gr.update(interactive=False),gr.update(interactive=False), gr.update(interactive=False)\n",
        "\n",
        "    def activate():\n",
        "        return gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True)\n",
        "\n",
        "    def update_corpus():\n",
        "        smantic.reload_indexes()\n",
        "        return gr.update(choices= [corpus for corpus in smantic.indexs])\n",
        "\n",
        "    def load_corpus(corpus_select):\n",
        "        st = smantic.load_corpus(corpus_select)\n",
        "        return gr.update(choices= st, value=st[0])\n",
        "\n",
        "    def search(input_search_txt, input_search_type, img_count, search_translate, use_local_images):\n",
        "        search_embedd = smantic.embedd_input(input_search_txt, search_translate)\n",
        "        images_legend = smantic.search_sim_images(search_embedd,type_search[input_search_type], img_count, use_local_images)\n",
        "        return images_legend\n",
        "\n",
        "    def update_legend_choice(r2):\n",
        "        if r2 == \"Pas de l√©gende\":\n",
        "            return gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=True)\n",
        "\n",
        "    def update_image_choice(r1):\n",
        "        if r1 == \"Urls\":\n",
        "            return gr.update(visible=True)\n",
        "        else:\n",
        "            return gr.update(visible=False)\n",
        "\n",
        "    def change_row(search_type):\n",
        "        print(search_type)\n",
        "        if search_type == \"Images & l√©gendes\":\n",
        "            return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)\n",
        "        elif search_type == \"Identifiants ARK (Gallica)\" :\n",
        "            return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    def load_df(file_path, file_ark_sep):\n",
        "        if file_ark_sep == '[ , ] virgule':\n",
        "            sep = \",\"\n",
        "        else:\n",
        "            sep= \";\"\n",
        "        print(file_path)\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, encoding=\"utf-8\", sep =sep)\n",
        "            l = len(df.columns)\n",
        "            return gr.update(value=df.head(5), visible=True), gr.update(choices=list(df.columns), visible=True), gr.update(choices=list(df.columns), visible=True), gr.update(visible=True), gr.update(visible=True)#, column_widths=[f\"{int(100/l)}%\"]*l)\n",
        "        except:\n",
        "            gr.Info(\"Le fichier csv n'a pas pu √™tre charg√©.V√©rifiez le s√©parateur csv utilis√© et assurez vous que le fichier est encod√© en utf-8\")\n",
        "            return gr.update(visible=False), gr.update(choices=[], visible=True), gr.update(choices=[], visible=True), gr.update(visible=False), gr.update(visible=False)#, column_widths=[f\"{int(100/l)}%\"]*l)\n",
        "\n",
        "    def load_df_ark(file_path, sep):\n",
        "        if sep == '[ , ] virgule':\n",
        "            sep = \",\"\n",
        "        else:\n",
        "            sep= \";\"\n",
        "        print(file_path)\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, encoding=\"utf-8\", sep =sep)\n",
        "            l = len(df.columns)\n",
        "            return gr.update(value=df.head(5), visible=True), gr.update(choices=list(df.columns), visible=True),  gr.update(visible=True)\n",
        "        except:\n",
        "            if file_path is not None:\n",
        "                gr.Info(\"Le fichier csv n'a pas pu √™tre charg√©. V√©rifiez le s√©parateur csv utilis√© et assurez vous que le fichier est encod√© en utf-8\")\n",
        "            return gr.update(visible=False), gr.update(visible=False),  gr.update(visible=False)\n",
        "\n",
        "    def load_dir_image(img_dir):\n",
        "        if img_dir == \"\":\n",
        "            return gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=True)\n",
        "\n",
        "    # Gradio UI\n",
        "    with gr.Blocks() as demo:\n",
        "        with gr.Tab(\"Recherche\"):\n",
        "            with gr.Row():\n",
        "                corpus_select = gr.Dropdown([], label=\"Corpus\", info=\"Choisissez un corpus\", value=0)\n",
        "            with gr.Row():\n",
        "                update_btn = gr.Button(\"Rafra√Æchir la liste des corpus\")\n",
        "            with gr.Row():\n",
        "                search_type = gr.Dropdown([\"Texte & Image\", \"Image\", \"Texte\"], label=\"Type de recherche\", info=\"Choisissez un type de recherche\", value=\"Texte & Image\", interactive = False)\n",
        "                with gr.Column():\n",
        "                    search_txt = gr.Textbox(label=\"Recherche\", info=\"Texte pour la recherche d'images\", interactive = False)\n",
        "                    search_translate = gr.Checkbox(label=\"Traduire la recherche en anglais\", value=True, interactive = False)\n",
        "                    use_local_images = gr.Checkbox(label=\"Utiliser les images locales (plus rapide)\", value=True, interactive = False)\n",
        "            with gr.Row():\n",
        "                img_count = gr.Slider(1, 25, value=5, label=\"Nombre d'images\", info=\"Choisissez le nombre d'images √† rechercher\", step=1, interactive = False)\n",
        "            with gr.Row():\n",
        "                search_btn = gr.Button(\"Rechercher des images\", interactive = False)\n",
        "            with gr.Row():\n",
        "                gallery = gr.Gallery(label=\"Generated images\", show_label=False, elem_id=\"gallery\", columns=[3], rows=[1], object_fit=\"fill\", height=\"auto\", interactive = False)\n",
        "        with gr.Tab(\"Cr√©er un corpus\") :\n",
        "            with gr.Column():\n",
        "                training_type = gr.Dropdown([\"Dossier d'images\", \"Identifiants ARK (Gallica)\", \"Images & l√©gendes\"], label=\"Type de corpus\", info=\"Choisissez un type de corpus\", interactive = True)\n",
        "\n",
        "            # Type : Dossier\n",
        "            with gr.Column(visible=False) as groupDir:\n",
        "                gr.HTML(value=\"<h1 style=\\\"margin-top:5px\\\"> Corpus d'images dans un dossier</h1>\")\n",
        "                with gr.Row():\n",
        "                    coll_name_dir_img = gr.Textbox(label=\"Nom de collection\", info=\"Entrez le nom de votre collection\", interactive = True)\n",
        "                with gr.Group():\n",
        "                    with gr.Column():\n",
        "                        img_dir = gr.Textbox(label=\"Chemin du dossier d'images\", info=\"/chemin/du/dossier/\",interactive = True)\n",
        "                with gr.Column(visible=False) as group_dir_img_columns:\n",
        "                    with gr.Row():\n",
        "                        use_filename_dir = gr.Checkbox(label = \"Utiliser les noms de fichiers comme l√©gendes\", value=False, visible=True, interactive = True)\n",
        "                    search_btn_dir_img = gr.Button(\"Cr√©er et entrainer le corpus\", interactive = True, visible=True)\n",
        "\n",
        "            # Type : Ark\n",
        "            with gr.Column(visible=False) as groupArk:\n",
        "                gr.HTML(value=\"<h1 style=\\\"margin-top:5px\\\"> Corpus Gallica (identifiants ARK)</h1>\")\n",
        "                with gr.Row():\n",
        "                    coll_name_ark = gr.Textbox(label=\"Nom de collection\", info=\"Entrez le nom de votre collection\", interactive = True)\n",
        "                with gr.Group():\n",
        "                    with gr.Column():\n",
        "                        file_sep_ark = gr.Radio(choices=['[ ; ] point-virgule', '[ , ] virgule'], label = \"S√©parateur CSV\",  interactive = True, value='[ ; ] point-virgule')\n",
        "                        file_ark = gr.File(label=\"Fichier CSV du corpus\", file_types=[\".csv\"])\n",
        "                with gr.Column(visible=False) as group_ark_columns:\n",
        "                    df_ark = gr.Dataframe(interactive = False, visible=True)\n",
        "                    with gr.Row():\n",
        "                        dropdown_ark = gr.Dropdown(choices=[], label=\"Colonne ARK\", info=\"S√©lectionnez une colonne\", interactive = True)\n",
        "                    with gr.Row():\n",
        "                        keep_local_ark = gr.Checkbox(label = \"Conserver les images en local\", value=True, visible=True, interactive = True)\n",
        "\n",
        "                    search_btn_image = gr.Button(\"Cr√©er et entrainer le corpus\", interactive = True, visible=True)\n",
        "\n",
        "            # Type: Local CSV\n",
        "            with gr.Column(visible=False) as groupImages:\n",
        "                gr.HTML(value=\"<h1 style=\\\"margin-top:5px\\\"> Corpus images & l√©gendes</h1>\")\n",
        "                with gr.Row():\n",
        "                    coll_name_image = gr.Textbox(label=\"Nom du corpus\", info=\"Entrez le nom de votre corpus\", interactive = True)\n",
        "                with gr.Group():\n",
        "                    with gr.Column():\n",
        "                        file_image = gr.File(label=\"Fichier CSV du corpus\", file_types=[\".csv\"])\n",
        "                        file_sep_image = gr.Radio(choices=['[ ; ] point-virgule', '[ , ] virgule'], label = \"S√©parateur CSV\",  interactive = True, value='[ ; ] point-virgule')\n",
        "                with gr.Column(visible=False) as groupImages_columns:\n",
        "                    df = gr.Dataframe(interactive = False, visible=False)\n",
        "                    with gr.Column():\n",
        "                        with gr.Column():\n",
        "                            r = gr.Radio(label=\"Type des chemins d'images\", choices = [\"Chemins locaux\", \"Urls\"], value=\"Chemins locaux\", interactive = True)\n",
        "                            dropdown_image = gr.Dropdown(choices=[], label=\"Colonne\", info=\"S√©lectionnez une colonne\", interactive = True)\n",
        "                            keep_local_image = gr.Checkbox(label = \"Conserver les images en local\", value=True, visible=False, interactive = True)\n",
        "                        with gr.Column():\n",
        "                            r2 = gr.Radio(label = \"Langue des l√©gendes\",choices = [\"Fran√ßais\", \"Anglais\", \"Pas de l√©gende\"], value=\"Fran√ßais\", interactive = True)\n",
        "                            dropdown_legend = gr.Dropdown(choices=[], label=\"Colonne\", info=\"S√©lectionnez une colonne\", interactive = True)\n",
        "                    search_ark_csv = gr.Button(\"Lancer la collecte et les traitements\", interactive = True, visible=True)\n",
        "        with gr.Accordion(label=\"Logs\", open=False):\n",
        "            logs = gr.Textbox()\n",
        "\n",
        "        search_btn.click(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, search_translate, use_local_images]).then(search, inputs=[search_txt,search_type, img_count, search_translate, use_local_images], outputs=[gallery]).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, search_translate, use_local_images])\n",
        "        update_btn.click(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, search_translate, use_local_images]).then(update_corpus, outputs=[corpus_select]).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, search_translate, use_local_images])\n",
        "\n",
        "        search_ark_csv.click(fn=search_csv_fn, inputs=[coll_name_image, file_image, dropdown_image, keep_local_image, file_sep_image, r2, dropdown_legend, r])\n",
        "        search_btn_image.click(fn=search_ark_fn, inputs=[coll_name_ark, file_ark, dropdown_ark, keep_local_ark,file_sep_ark])\n",
        "        search_btn_dir_img.click(fn=search_dir_fn, inputs=[coll_name_dir_img, img_dir, use_filename_dir])\n",
        "\n",
        "        corpus_select.change(fn=deactivate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, search_translate, use_local_images]).then(load_corpus, inputs=[corpus_select], outputs=[search_type], show_progress=True).then(fn=activate, outputs=[corpus_select, update_btn, search_type, search_txt, img_count, search_btn, search_translate, use_local_images])\n",
        "\n",
        "        training_type.change(fn=change_row, inputs=[training_type], outputs=[groupDir, groupArk, groupImages])\n",
        "        file_image.change(fn=load_df, inputs=[file_image, file_sep_image], outputs=[df, dropdown_legend, dropdown_image, groupImages_columns])\n",
        "        file_ark.change(fn=load_df_ark, inputs=[file_ark, file_sep_ark], outputs=[df_ark, dropdown_ark, group_ark_columns])\n",
        "        img_dir.change(fn=load_dir_image, inputs=[img_dir], outputs=[group_dir_img_columns])\n",
        "        r2.change(fn=update_legend_choice, inputs=[r2], outputs=[dropdown_legend])\n",
        "        r.change(fn=update_image_choice, inputs=[r], outputs=[keep_local_image])\n",
        "        #demo.load(read_logs, None, logs, every=1)\n",
        "    demo.launch(debug=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AeBCGs7s-qWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}